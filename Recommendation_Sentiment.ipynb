{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install necessary packages to run the code"
      ],
      "metadata": {
        "id": "zQwQrrUhwLVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Install newspaper3k package used in web scraping and corpus building\n",
        "!pip install newspaper3k"
      ],
      "metadata": {
        "id": "JNw5nlWXwKvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31dad44d-921b-4e9a-a5f0-0e1319f262d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.9/dist-packages (0.2.8)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (4.11.2)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (4.9.2)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (8.4.0)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (6.0)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (6.0.10)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (1.2.0)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (2.27.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.9/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.1->newspaper3k) (4.65.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.1->newspaper3k) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.1->newspaper3k) (1.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->newspaper3k) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->newspaper3k) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->newspaper3k) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.12)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.9/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.12.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.9/dist-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install emoji package\n",
        "!pip install --upgrade emoji"
      ],
      "metadata": {
        "id": "AQb4fgGLwCxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f1e3b9-e6a7-41d0-c0b1-66b9352b34ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.9/dist-packages (2.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autheticating using Twitter API key and Getting Twitter User data"
      ],
      "metadata": {
        "id": "YZqqqhOYuBxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "#to scrape Twitter\n",
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "#warning    \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "JeJ9HkypuF80"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Twitter API tokens and keys are set up. To authenticate a user's request and ensure only\n",
        "# authorized users can access the API, specific keys and tokens are needed.\n",
        "CONSUMER_KEY = 'TZ7i40WeANa0gWBpytGsjc7se'\n",
        "CONSUMER_SECRET = 'NRWRlNs01IWFl8xfP6Xsct3gdb8lkOI2kBCNuVMkby47OMeD48'\n",
        "OAUTH_TOKEN = '2474122806-dWEoJhdMtwoPwFIvnZGQQk2qw5XQScTIjQ6Y92T'\n",
        "OAUTH_TOKEN_SECRET = '2sLvxi1Zn6MhQr1VJVU8x6Dvjm2EMFIALHXM5vqnZxxCf'\n",
        " \n",
        "# Creates an instance of 'OAuthHandler' class, which is used to authenticate Twitter API\n",
        "authentication = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET) \n",
        "# For the authenticated user, sets the access token and access token secret\n",
        "authentication.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET) \n",
        "\n",
        "# Generates a new instance of the tweepy library's API class\n",
        "api = tweepy.API(authentication, wait_on_rate_limit = True) "
      ],
      "metadata": {
        "id": "FwmHY4wYuHo5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to get user's tweets"
      ],
      "metadata": {
        "id": "dBjBNzUNul5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function fetchRetweets to get users who retweeted on the top 20 tweets of news channels\n",
        "# TopNewsChannels is a list of Twitter news channel handles, \n",
        "# TweetsCount is the number of tweets for each news channel\n",
        "def fetchRetweets(topNewsChannels,tweetsCount):\n",
        "  \n",
        "# Initializing a list to store user's data\n",
        "    usersCollection = []\n",
        "\n",
        "# Iterating over newschannels list \n",
        "    for channel in topNewsChannels:\n",
        "        tweets = api.user_timeline(screen_name=channel, count= tweetsCount)   #fetching number of tweets for a news channel using user_timeline method\n",
        "# Iterating over each tweet and then fetches retweets of each tweet using get_retweets\n",
        "        for tweet in tweets:\n",
        "            retweets = api.get_retweets(tweet.id)\n",
        "# Iterating over each retweet and creates a user dictionary containing user data from that handle\n",
        "            for retweet in retweets:\n",
        "                user = {\n",
        "                    \"Users\": retweet.user.screen_name,\n",
        "                    \"FollowersCount\": retweet.user.followers_count / max(1, retweet.user.friends_count),\n",
        "                    \"TotalTweets\": retweet.user.statuses_count\n",
        "                }\n",
        "# Adding dictionary to list\n",
        "                usersCollection.append(user)\n",
        "\n",
        "# Returning dataframe with list of dictionaries  \n",
        "    return pd.DataFrame(usersCollection)"
      ],
      "metadata": {
        "id": "5dNzFYwNuUX7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The news channel twitter handles tags for extraction of tweets and users\n",
        "ChannelHandles = [\"FoxNews\", \"nytimes\",\"NBCNews\"]\n",
        "usersOfChannels = fetchRetweets(ChannelHandles,20)\n",
        "# Printing the fetched users\n",
        "usersOfChannels"
      ],
      "metadata": {
        "id": "gySmI-WJvm40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "0b694d2d-76a4-4898-c11f-ff83454c2cb3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Users  FollowersCount  TotalTweets\n",
              "0       mallubang77        0.271908       271402\n",
              "1     JDiaz10957042        0.149606         1898\n",
              "2     KeiNishikawa3        0.817204       906476\n",
              "3     DanielaRallis        0.066856         5759\n",
              "4        Steve_1224        0.964835        50809\n",
              "..              ...             ...          ...\n",
              "581     SDK_Resists        1.010965       141399\n",
              "582     ImmaBioloG2        0.497696         4427\n",
              "583    dartgunintel        0.250749       255492\n",
              "584       filafresh        1.642738      2806310\n",
              "585  adudeandhisart        0.169336        27590\n",
              "\n",
              "[586 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-240116ab-c087-454a-8f25-62284b6d4b0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Users</th>\n",
              "      <th>FollowersCount</th>\n",
              "      <th>TotalTweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mallubang77</td>\n",
              "      <td>0.271908</td>\n",
              "      <td>271402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JDiaz10957042</td>\n",
              "      <td>0.149606</td>\n",
              "      <td>1898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KeiNishikawa3</td>\n",
              "      <td>0.817204</td>\n",
              "      <td>906476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DanielaRallis</td>\n",
              "      <td>0.066856</td>\n",
              "      <td>5759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Steve_1224</td>\n",
              "      <td>0.964835</td>\n",
              "      <td>50809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>SDK_Resists</td>\n",
              "      <td>1.010965</td>\n",
              "      <td>141399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>ImmaBioloG2</td>\n",
              "      <td>0.497696</td>\n",
              "      <td>4427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583</th>\n",
              "      <td>dartgunintel</td>\n",
              "      <td>0.250749</td>\n",
              "      <td>255492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>filafresh</td>\n",
              "      <td>1.642738</td>\n",
              "      <td>2806310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>585</th>\n",
              "      <td>adudeandhisart</td>\n",
              "      <td>0.169336</td>\n",
              "      <td>27590</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>586 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-240116ab-c087-454a-8f25-62284b6d4b0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-240116ab-c087-454a-8f25-62284b6d4b0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-240116ab-c087-454a-8f25-62284b6d4b0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Duplicate Users\n"
      ],
      "metadata": {
        "id": "LWuNLOhB-JVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing duplicate users, as same user may retweet many times\n",
        "# Filtering for rows where TotalTweets is greater than 5 and \n",
        "# Popularity is greater than 1, resetting the index \n",
        "usersOfChannels.drop_duplicates(inplace = True)\n",
        "# To make sure that all users are authentic let's filter them based on their popularity and their twitter activity.\n",
        "usersOfChannels = usersOfChannels[(usersOfChannels.TotalTweets > 5) & (usersOfChannels.FollowersCount > 1)]\n",
        "usersOfChannels = usersOfChannels.reset_index(drop=True)\n",
        "# The numbe of users is the first value of the tuple\n",
        "usersOfChannels.shape"
      ],
      "metadata": {
        "id": "5cRLQbPXwJo2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a0da7f-5703-4bdb-f734-e68115279f5c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have list of active users from which we can get their information. Following function will extract each user's top 15 tweets\n"
      ],
      "metadata": {
        "id": "7Faf2jh4w0lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to fetch the most recent 15 tweets of a given user using the Twitter API and returns them as a list.\n",
        "def fetchUserTweets(user):\n",
        "# Fetch top 15 tweets of the users fetched earlier\n",
        "    usertweets = api.user_timeline(screen_name = user, count = 15, tweet_mode = 'extended')\n",
        "    toptweets = [tweet.retweeted_status.full_text if tweet.full_text.startswith(\"RT @\") else tweet.full_text for tweet in usertweets]\n",
        "    return toptweets\n",
        "  \n",
        "\n",
        "tweets_list = []\n",
        "# Call fetchUserTweets on user handle from the usersOfChannels column and storing in tweets_list\n",
        "for user in usersOfChannels['Users']:\n",
        "    tweets = fetchUserTweets(str(user))\n",
        "    tweets_list.append(tweets)\n",
        "# Add UserTweets columns that will contain list of lists of tweets for each user handle\n",
        "usersOfChannels[\"UserTweets\"] = tweets_list"
      ],
      "metadata": {
        "id": "sc7ryETTwyL0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usersOfChannels"
      ],
      "metadata": {
        "id": "T1ecVcVsQ5E8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "95324e06-7c19-4146-8f86-44cf302173b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Users  FollowersCount  TotalTweets  \\\n",
              "0        BootsieJazz        4.939855         8007   \n",
              "1       unrulysoljah        1.893738       218527   \n",
              "2      FaithTiffany2        1.093750        54665   \n",
              "3       FrittsJensen      204.000000        24826   \n",
              "4    AustinCCollier1        1.050483       104918   \n",
              "..               ...             ...          ...   \n",
              "97     CliftonKinnie        4.877106        29633   \n",
              "98          yeskyyes       41.449612        14948   \n",
              "99        MOMO198425        2.975610        10705   \n",
              "100      SDK_Resists        1.010965       141399   \n",
              "101        filafresh        1.642738      2806310   \n",
              "\n",
              "                                            UserTweets  \n",
              "0    [Always remember that whenever a democrat says...  \n",
              "1    [I am saddened how some gospel musicians treat...  \n",
              "2    [Our Girl https://t.co/2gYkZ5OaHS, Senator Nan...  \n",
              "3    [@ChasingKensho @FoxNews They are literally ta...  \n",
              "4    [TURNING THE TABLES: The suspects chose the wr...  \n",
              "..                                                 ...  \n",
              "97   [These four House Republicans voted against th...  \n",
              "98   [High-Tech Neocannibalism\\n高科技新食人主义 https://t....  \n",
              "99   [@laomanshujuku 好像还有福建, 更正：：理论上央行可以追踪数字货币（不是现金...  \n",
              "100  [Speaker McCarthy’s debt limit proposal would ...  \n",
              "101  [Minute Maid &gt; Tropicana\\n\\nFinal: #Astros ...  \n",
              "\n",
              "[102 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b3afef2-0c1f-4d95-894a-87126da7f8cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Users</th>\n",
              "      <th>FollowersCount</th>\n",
              "      <th>TotalTweets</th>\n",
              "      <th>UserTweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BootsieJazz</td>\n",
              "      <td>4.939855</td>\n",
              "      <td>8007</td>\n",
              "      <td>[Always remember that whenever a democrat says...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unrulysoljah</td>\n",
              "      <td>1.893738</td>\n",
              "      <td>218527</td>\n",
              "      <td>[I am saddened how some gospel musicians treat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FaithTiffany2</td>\n",
              "      <td>1.093750</td>\n",
              "      <td>54665</td>\n",
              "      <td>[Our Girl https://t.co/2gYkZ5OaHS, Senator Nan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FrittsJensen</td>\n",
              "      <td>204.000000</td>\n",
              "      <td>24826</td>\n",
              "      <td>[@ChasingKensho @FoxNews They are literally ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AustinCCollier1</td>\n",
              "      <td>1.050483</td>\n",
              "      <td>104918</td>\n",
              "      <td>[TURNING THE TABLES: The suspects chose the wr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>CliftonKinnie</td>\n",
              "      <td>4.877106</td>\n",
              "      <td>29633</td>\n",
              "      <td>[These four House Republicans voted against th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>yeskyyes</td>\n",
              "      <td>41.449612</td>\n",
              "      <td>14948</td>\n",
              "      <td>[High-Tech Neocannibalism\\n高科技新食人主义 https://t....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>MOMO198425</td>\n",
              "      <td>2.975610</td>\n",
              "      <td>10705</td>\n",
              "      <td>[@laomanshujuku 好像还有福建, 更正：：理论上央行可以追踪数字货币（不是现金...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>SDK_Resists</td>\n",
              "      <td>1.010965</td>\n",
              "      <td>141399</td>\n",
              "      <td>[Speaker McCarthy’s debt limit proposal would ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>filafresh</td>\n",
              "      <td>1.642738</td>\n",
              "      <td>2806310</td>\n",
              "      <td>[Minute Maid &amp;gt; Tropicana\\n\\nFinal: #Astros ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b3afef2-0c1f-4d95-894a-87126da7f8cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b3afef2-0c1f-4d95-894a-87126da7f8cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b3afef2-0c1f-4d95-894a-87126da7f8cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing tweets "
      ],
      "metadata": {
        "id": "1nOS-F-BxF3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing neccesary libraries for preprocessing the tweets of the each user\n",
        "import spacy \n",
        "import re\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "# Loads the small english language model called spacy while also creating a set of all the words present in the vocabulary of the model\n",
        "nlp = spacy.load(\"en_core_web_sm\") \n",
        "stop = set(STOP_WORDS) # Creates a set of stop words\n",
        "exclude = set(string.punctuation) # Creates a set of unctuation marks imported from the \"string\" module\n",
        "words = set(nlp.vocab.strings)"
      ],
      "metadata": {
        "id": "ToOgu2kYxDI4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defined a function called \"preprocessing\" which takes in the users tweets as the argument and performs several text preprocessing steps on them \n",
        "\n",
        "def preprocessing(usertweets):\n",
        "    # Clean of tweets\n",
        "    cleanedData = []\n",
        "    for usertweet in usertweets:\n",
        "        tweet = re.sub('http\\S+', '', usertweet) # Remove links\n",
        "        tweet = re.sub('RT', '', tweet) # Remove RT of retweet\n",
        "        tweet = re.sub('@[^\\s]+','',tweet) # Remove usernames \n",
        "        tweet = \"\".join([char for char in tweet if char not in string.punctuation]) # Remove punctuations\n",
        "        tweet = tweet.lower() # Converting to lowercase letters\n",
        "        tweet = ' '.join([word for word in tweet.split() if word not in (stop)]) # Removing stop words\n",
        "        tweet = ' '.join([word for word in tweet.split() if len(word)>2]) # Removes any word which has less than 2 letters in it\n",
        "        cleanedData.append(tweet)\n",
        "\n",
        "    cleanedData = ' '.join(cleanedData) # Joining all tweets\n",
        "\n",
        "    # Tokenization\n",
        "    processedTweets = nlp(cleanedData) \n",
        "\n",
        "    # Stemming (lemmatization in spacy)\n",
        "    processedTweets = [token.lemma_ for token in processedTweets] # Apply the lemmetization\n",
        "\n",
        "    processedTweets = [word for word in processedTweets if len(word)>2] # Filter out the words which has less than 2 letters in it\n",
        "\n",
        "    processedTweets = ' '.join(w for w in processedTweets if w in words) # Filter out the words which are not present in the spacy vocabulary\n",
        "\n",
        "    return processedTweets # Return the processes tweets of a user\n"
      ],
      "metadata": {
        "id": "D_c-aeUTxOVU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the preprocessing func to each row in the \"UserTweets\" column and creating a new column \"ptweets\" to store the resultant preprocessed tweets\n",
        "usersOfChannels[\"ptweets\"] = usersOfChannels['UserTweets'].apply(lambda x : preprocessing(x))\n"
      ],
      "metadata": {
        "id": "yXC_LCcJxP7D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the resultant processed data\n",
        "usersOfChannels"
      ],
      "metadata": {
        "id": "VfZa2pElO2Zr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c2fd79b2-6246-4c3b-b151-f10db54a1a57"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Users  FollowersCount  TotalTweets  \\\n",
              "0        BootsieJazz        4.939855         8007   \n",
              "1       unrulysoljah        1.893738       218527   \n",
              "2      FaithTiffany2        1.093750        54665   \n",
              "3       FrittsJensen      204.000000        24826   \n",
              "4    AustinCCollier1        1.050483       104918   \n",
              "..               ...             ...          ...   \n",
              "97     CliftonKinnie        4.877106        29633   \n",
              "98          yeskyyes       41.449612        14948   \n",
              "99        MOMO198425        2.975610        10705   \n",
              "100      SDK_Resists        1.010965       141399   \n",
              "101        filafresh        1.642738      2806310   \n",
              "\n",
              "                                            UserTweets  \\\n",
              "0    [Always remember that whenever a democrat says...   \n",
              "1    [I am saddened how some gospel musicians treat...   \n",
              "2    [Our Girl https://t.co/2gYkZ5OaHS, Senator Nan...   \n",
              "3    [@ChasingKensho @FoxNews They are literally ta...   \n",
              "4    [TURNING THE TABLES: The suspects chose the wr...   \n",
              "..                                                 ...   \n",
              "97   [These four House Republicans voted against th...   \n",
              "98   [High-Tech Neocannibalism\\n高科技新食人主义 https://t....   \n",
              "99   [@laomanshujuku 好像还有福建, 更正：：理论上央行可以追踪数字货币（不是现金...   \n",
              "100  [Speaker McCarthy’s debt limit proposal would ...   \n",
              "101  [Minute Maid &gt; Tropicana\\n\\nFinal: #Astros ...   \n",
              "\n",
              "                                               ptweets  \n",
              "0    remember democrat say exact opposite true ford...  \n",
              "1    gospel musician treat house god justifies not ...  \n",
              "2    girl senator nancy schaefer wages war child pr...  \n",
              "3    literally target disabled child dutch governme...  \n",
              "4    turn table suspect choose wrong home invade kn...  \n",
              "..                                                 ...  \n",
              "97   house republicans vote gop debt limit bill man...  \n",
              "98   break argentina announce pay chinese import yu...  \n",
              "99                                                      \n",
              "100  speaker mccarthy debt limit proposal wreck eco...  \n",
              "101  minute maid tropicana final rays happen that l...  \n",
              "\n",
              "[102 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f859423a-b451-4641-b94e-43686ff90497\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Users</th>\n",
              "      <th>FollowersCount</th>\n",
              "      <th>TotalTweets</th>\n",
              "      <th>UserTweets</th>\n",
              "      <th>ptweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BootsieJazz</td>\n",
              "      <td>4.939855</td>\n",
              "      <td>8007</td>\n",
              "      <td>[Always remember that whenever a democrat says...</td>\n",
              "      <td>remember democrat say exact opposite true ford...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unrulysoljah</td>\n",
              "      <td>1.893738</td>\n",
              "      <td>218527</td>\n",
              "      <td>[I am saddened how some gospel musicians treat...</td>\n",
              "      <td>gospel musician treat house god justifies not ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FaithTiffany2</td>\n",
              "      <td>1.093750</td>\n",
              "      <td>54665</td>\n",
              "      <td>[Our Girl https://t.co/2gYkZ5OaHS, Senator Nan...</td>\n",
              "      <td>girl senator nancy schaefer wages war child pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FrittsJensen</td>\n",
              "      <td>204.000000</td>\n",
              "      <td>24826</td>\n",
              "      <td>[@ChasingKensho @FoxNews They are literally ta...</td>\n",
              "      <td>literally target disabled child dutch governme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AustinCCollier1</td>\n",
              "      <td>1.050483</td>\n",
              "      <td>104918</td>\n",
              "      <td>[TURNING THE TABLES: The suspects chose the wr...</td>\n",
              "      <td>turn table suspect choose wrong home invade kn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>CliftonKinnie</td>\n",
              "      <td>4.877106</td>\n",
              "      <td>29633</td>\n",
              "      <td>[These four House Republicans voted against th...</td>\n",
              "      <td>house republicans vote gop debt limit bill man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>yeskyyes</td>\n",
              "      <td>41.449612</td>\n",
              "      <td>14948</td>\n",
              "      <td>[High-Tech Neocannibalism\\n高科技新食人主义 https://t....</td>\n",
              "      <td>break argentina announce pay chinese import yu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>MOMO198425</td>\n",
              "      <td>2.975610</td>\n",
              "      <td>10705</td>\n",
              "      <td>[@laomanshujuku 好像还有福建, 更正：：理论上央行可以追踪数字货币（不是现金...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>SDK_Resists</td>\n",
              "      <td>1.010965</td>\n",
              "      <td>141399</td>\n",
              "      <td>[Speaker McCarthy’s debt limit proposal would ...</td>\n",
              "      <td>speaker mccarthy debt limit proposal wreck eco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>filafresh</td>\n",
              "      <td>1.642738</td>\n",
              "      <td>2806310</td>\n",
              "      <td>[Minute Maid &amp;gt; Tropicana\\n\\nFinal: #Astros ...</td>\n",
              "      <td>minute maid tropicana final rays happen that l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f859423a-b451-4641-b94e-43686ff90497')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f859423a-b451-4641-b94e-43686ff90497 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f859423a-b451-4641-b94e-43686ff90497');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering users according to their interests using k-means clustering"
      ],
      "metadata": {
        "id": "QI_8gECuxrlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imported various modules and  functions to perform text clustering analysis and grouping \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "e4vrsS57xjk1"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To cluster users based on their twitter contents we converted tweets into vectorized form using TF-IDF vectorizer\n",
        "# The object is configured to exclude words that are too common or too rare and to limit the feature space size. \n",
        "# The resulting matrix will be used for text clustering.\n",
        "\n",
        "# Utilizing TfidfVectorizer, text input can be preprocessed and changed into a numerical format. \n",
        "# For each phrase in the corpus, the phrase Frequency-Inverse Document Frequency (TF-IDF) score is calculated. \n",
        "text_transform = TfidfVectorizer(max_df=0.9, max_features=200000, min_df=0.1, use_idf=True)\n",
        "# Builds a vocabulary, and calculates the IDF score for each item in the lexicon.\n",
        "text_transform.fit(usersOfChannels.ptweets)\n",
        "# Fits 'ptweets' attribute and transform the text into numerical format matrix\n",
        "tfidf_matrix = text_transform.transform(usersOfChannels.ptweets)\n"
      ],
      "metadata": {
        "id": "diP_UlKLxuKG"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix.toarray()"
      ],
      "metadata": {
        "id": "RTfJFSzMxvMm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dfe6d83-fe14-417a-c4ae-934c5a1d91a1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.10549471, 0.        ,\n",
              "        0.28816657],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.11162536, ..., 0.07269206, 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix.shape"
      ],
      "metadata": {
        "id": "d0tZ6GcexwtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44278ac4-524f-4887-af95-a066ef1975d5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 238)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe with feature names and user handles and tf-idf scores for each word in each user's messages\n",
        "pd.DataFrame(tfidf_matrix.toarray(), columns=text_transform.get_feature_names_out(), index = usersOfChannels.Users)"
      ],
      "metadata": {
        "id": "oEd58IKQxzdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "2318eec6-ea11-4d09-ec0b-42cdee8f50e6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 100  2020  abortion    access    accord       act       age  \\\n",
              "Users                                                                          \n",
              "BootsieJazz      0.0   0.0  0.000000  0.000000  0.000000  0.141144  0.000000   \n",
              "unrulysoljah     0.0   0.0  0.000000  0.170024  0.000000  0.000000  0.158524   \n",
              "FaithTiffany2    0.0   0.0  0.111625  0.108789  0.000000  0.000000  0.000000   \n",
              "FrittsJensen     0.0   0.0  0.000000  0.166354  0.000000  0.000000  0.155102   \n",
              "AustinCCollier1  0.0   0.0  0.000000  0.112550  0.000000  0.000000  0.209875   \n",
              "...              ...   ...       ...       ...       ...       ...       ...   \n",
              "CliftonKinnie    0.0   0.0  0.123388  0.000000  0.112118  0.000000  0.000000   \n",
              "yeskyyes         0.0   0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "MOMO198425       0.0   0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "SDK_Resists      0.0   0.0  0.000000  0.000000  0.000000  0.101581  0.000000   \n",
              "filafresh        0.0   0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "                 allegedly    allow   america  ...  wednesday  week     white  \\\n",
              "Users                                          ...                              \n",
              "BootsieJazz        0.15788  0.00000  0.244463  ...   0.000000   0.0  0.000000   \n",
              "unrulysoljah       0.00000  0.00000  0.000000  ...   0.155166   0.0  0.149005   \n",
              "FaithTiffany2      0.00000  0.00000  0.084225  ...   0.000000   0.0  0.000000   \n",
              "FrittsJensen       0.00000  0.00000  0.000000  ...   0.000000   0.0  0.000000   \n",
              "AustinCCollier1    0.11255  0.00000  0.000000  ...   0.000000   0.0  0.000000   \n",
              "...                    ...      ...       ...  ...        ...   ...       ...   \n",
              "CliftonKinnie      0.00000  0.00000  0.000000  ...   0.000000   0.0  0.000000   \n",
              "yeskyyes           0.00000  0.00000  0.173927  ...   0.000000   0.0  0.000000   \n",
              "MOMO198425         0.00000  0.00000  0.000000  ...   0.000000   0.0  0.000000   \n",
              "SDK_Resists        0.00000  0.09958  0.000000  ...   0.000000   0.0  0.000000   \n",
              "filafresh          0.00000  0.00000  0.000000  ...   0.000000   0.0  0.000000   \n",
              "\n",
              "                      win     woman      work  world      year  york       you  \n",
              "Users                                                                           \n",
              "BootsieJazz      0.000000  0.360871  0.000000    0.0  0.105495   0.0  0.288167  \n",
              "unrulysoljah     0.174457  0.000000  0.127529    0.0  0.000000   0.0  0.000000  \n",
              "FaithTiffany2    0.000000  0.248661  0.000000    0.0  0.072692   0.0  0.000000  \n",
              "FrittsJensen     0.000000  0.000000  0.000000    0.0  0.000000   0.0  0.000000  \n",
              "AustinCCollier1  0.000000  0.000000  0.000000    0.0  0.075206   0.0  0.000000  \n",
              "...                   ...       ...       ...    ...       ...   ...       ...  \n",
              "CliftonKinnie    0.000000  0.091621  0.000000    0.0  0.160704   0.0  0.000000  \n",
              "yeskyyes         0.000000  0.000000  0.000000    0.0  0.000000   0.0  0.000000  \n",
              "MOMO198425       0.000000  0.000000  0.000000    0.0  0.000000   0.0  0.000000  \n",
              "SDK_Resists      0.000000  0.000000  0.170454    0.0  0.000000   0.0  0.000000  \n",
              "filafresh        0.258531  0.000000  0.000000    0.0  0.000000   0.0  0.000000  \n",
              "\n",
              "[102 rows x 238 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8b7dbcf-5b2a-49e7-a493-97104f51558e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>100</th>\n",
              "      <th>2020</th>\n",
              "      <th>abortion</th>\n",
              "      <th>access</th>\n",
              "      <th>accord</th>\n",
              "      <th>act</th>\n",
              "      <th>age</th>\n",
              "      <th>allegedly</th>\n",
              "      <th>allow</th>\n",
              "      <th>america</th>\n",
              "      <th>...</th>\n",
              "      <th>wednesday</th>\n",
              "      <th>week</th>\n",
              "      <th>white</th>\n",
              "      <th>win</th>\n",
              "      <th>woman</th>\n",
              "      <th>work</th>\n",
              "      <th>world</th>\n",
              "      <th>year</th>\n",
              "      <th>york</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Users</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BootsieJazz</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.15788</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.244463</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.360871</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.105495</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.288167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unrulysoljah</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.170024</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.158524</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.155166</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.149005</td>\n",
              "      <td>0.174457</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.127529</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FaithTiffany2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111625</td>\n",
              "      <td>0.108789</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.084225</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.248661</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.072692</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FrittsJensen</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166354</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.155102</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AustinCCollier1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.112550</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.209875</td>\n",
              "      <td>0.11255</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.075206</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CliftonKinnie</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.123388</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.112118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.091621</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.160704</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yeskyyes</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.173927</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MOMO198425</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SDK_Resists</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.101581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.09958</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.170454</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filafresh</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.258531</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102 rows × 238 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8b7dbcf-5b2a-49e7-a493-97104f51558e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8b7dbcf-5b2a-49e7-a493-97104f51558e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8b7dbcf-5b2a-49e7-a493-97104f51558e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this generated Tf-Idf matrix we can cluster the users."
      ],
      "metadata": {
        "id": "tE1M11Q3x3pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_clusters = 3 # Take count to make clusters\n",
        "\n",
        "# Create a kmeans object and setting the parameter values\n",
        "kmeans = KMeans(n_clusters=total_clusters, init='k-means++', max_iter=100, n_init=1)\n",
        "\n",
        "# Fit the kmeans algo to the tf-idf matrix that was generated (grouping the users based on similarity of their tweets data)\n",
        "kmeans.fit(tfidf_matrix)\n",
        "# Get cluster labels for each user \n",
        "clusters = kmeans.labels_.tolist()\n",
        "\n",
        "# Add cluster labels in the usersData \n",
        "usersOfChannels['Clusters'] = clusters"
      ],
      "metadata": {
        "id": "sTIZLcRgx1Qw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cluster centers and sorting the cluster centers array in descending order to get the most important features for each cluster first\n",
        "kmeans.cluster_centers_.argsort()[:, ::-1]"
      ],
      "metadata": {
        "id": "D1ykhUUyx5RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a3a9b4-ade9-43b4-827c-430f912e4ec4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[212, 157,  50,  18,  36,  37, 201, 107, 141,  72,  61,  75, 124,\n",
              "        171,  65,  28,  97,  25, 144,  21, 223, 131, 167,  14, 101,  55,\n",
              "         81,  47, 163, 122,  34, 114,  11, 116,  31, 185,  98, 147, 170,\n",
              "         77,  68, 115, 106,  78, 150,  92,  80,  62, 142, 181, 135, 183,\n",
              "         88, 130,  16, 200, 111, 209, 235, 108, 184, 175, 137, 126, 199,\n",
              "        186,  85, 206, 233,  94, 218,  22, 154,  67,  35,  15,   0,  56,\n",
              "          8,   9, 145,  20, 193,  29, 127, 190, 203,  57,  58,  82, 156,\n",
              "         26, 120, 196,  70, 148,  89, 217,   6, 205, 136, 188, 228, 139,\n",
              "         13, 173,  99, 232, 121,  66, 198, 187, 230,  63, 216,  23, 220,\n",
              "         33, 143, 132,  93,   2, 214, 123, 227, 192, 152, 100,  86,  44,\n",
              "         39, 215, 211, 174, 195,  41, 168,  38, 117,  87, 222,  49,  52,\n",
              "          7, 182, 177, 146,   1,  45,  64, 210, 219,  24, 158,  46, 133,\n",
              "        160,  51,   4,  12, 207, 221,  43, 234,  40,  32, 110,  48, 129,\n",
              "        229, 165, 178, 226, 166,  91, 119, 172, 213, 105,  79, 102, 180,\n",
              "        112,  10, 125,  96,   3, 149, 189, 237,   5, 155, 128, 140, 134,\n",
              "        197,  90, 104, 225, 151,  19, 202, 191, 176, 224, 208,  76, 138,\n",
              "         95, 164,  27,  74,  83,  73, 162, 118,  69, 231, 194, 159, 204,\n",
              "         30,  59, 153,  60,  42,  71,  84, 103,  54, 179, 109, 169, 113,\n",
              "        161,  17, 236,  53],\n",
              "       [ 21, 144, 150,  11, 188, 157, 171,  40, 172,  55, 168,  97, 235,\n",
              "        114, 121, 139,  32, 232, 204,  84, 199,  85,  23,  42, 207, 196,\n",
              "        225, 209, 129, 113, 141, 206, 180,  45, 111,   9,  31, 128,   6,\n",
              "         28, 226,  79, 109, 164, 119, 159, 152,  86, 193, 169, 160,  48,\n",
              "        165, 233, 212, 149,  94, 118,  39,  10,  30, 228,  12, 205,  54,\n",
              "        189, 195, 198,  57, 192,  49, 191, 223, 142, 148, 217,  33,  13,\n",
              "        161, 137,  90, 138,  78, 203,   4, 230,  73, 231,  82, 103,  91,\n",
              "         34, 162,   1, 224, 166, 184, 153, 125, 127,  17,  77, 104,  87,\n",
              "         51,  41,  71, 222, 215, 178, 234,  96, 185,   5,  18, 210,  27,\n",
              "        167,  50,  29, 115,   7,  22, 105,  76,  14, 100, 176, 229, 174,\n",
              "        132, 181,  95, 237, 134,   8, 135,  70,  19, 112,  80,  15,  88,\n",
              "        102,  66, 177,  53, 186, 120,  93,  59,  83, 190, 154, 117,   3,\n",
              "        163, 136,  81,  35,  72, 220,  37, 158, 197, 175,  24,  26,   2,\n",
              "         38, 122, 110, 155,  98, 182,  61, 216, 126,  25, 227, 123,  74,\n",
              "         75, 151, 156,  58, 131, 143,  63,  52, 202, 124,  47, 219,  56,\n",
              "         43, 179, 187, 173, 221, 200, 214, 146,  44, 170, 145, 201, 194,\n",
              "        133, 236, 183,  62,  20,  67, 108, 213,  46,  99,  92,  16, 218,\n",
              "        116,  60, 208,  65,  68,  69,   0,  89, 106, 101, 130, 211, 107,\n",
              "        147,  64,  36, 140],\n",
              "       [215,  35,  80, 223, 120, 142, 171, 144, 121, 212, 233, 125,  28,\n",
              "        234, 141, 207,  59,  60, 199, 213,  55, 167,  49, 150, 140,  69,\n",
              "        222, 211,  92,  75, 168, 209,  38, 230,  81,  24, 135, 202, 236,\n",
              "        225,  64, 227,  97, 179, 157, 208,  17,  11,  93, 106, 188, 237,\n",
              "        134,  82, 178, 110,  10, 163,  50, 139, 185, 218,  67,  87, 132,\n",
              "        138, 232, 197, 129, 166, 194, 159, 158,  99, 126, 151, 133, 117,\n",
              "         73, 165, 229,  63,  37,  52, 111,  76,  21,  85, 128, 114,  20,\n",
              "         96, 180,  34, 156, 175, 136,   9, 216,  12, 184,  46, 155,  65,\n",
              "         83,  56,  36, 176, 231, 221, 116,  91, 170,  88,  15,  89,  98,\n",
              "        146, 108,   3, 219,  26, 143, 174, 118,  71,  32,  79,   0, 147,\n",
              "         13,  78, 235,  77,  58,  40, 112, 193,  66,  39, 187, 226,  53,\n",
              "        145,  33, 201, 162,  74,  19,  95, 181,  68, 107, 190, 119, 186,\n",
              "        196, 124,  44, 205, 131, 123, 183, 130,  23,  86,   5,   1,  43,\n",
              "        206, 127, 214,   4, 154,  27,  14, 103, 149,  47, 204, 182, 102,\n",
              "          2, 203,  62,  70, 228,  22,  30, 161,   8,  16, 173, 137, 189,\n",
              "         42, 101, 210,  72, 198, 115,  31, 109,  45,  90,  18, 160, 122,\n",
              "        192, 172, 105, 177, 153, 200,  48,  61,  25, 191,  94, 220, 164,\n",
              "         54,  84,   7,  41, 224, 217, 195, 113,  29, 104, 100,   6,  57,\n",
              "        152, 148,  51, 169]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top words per cluster:\")\n",
        "# Get cluster centers and sorting the cluster centers array in descending order to get the most important features for each cluster first\n",
        "sorted_order = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
        "# Get list of feature names using get_feature_names_out that were generated in the text_tranform\n",
        "terms = text_transform.get_feature_names_out()\n",
        "# Iterate over clusters and printing top 10 terms of each cluster\n",
        "for i in range(total_clusters):\n",
        "    print (\"Cluster %d:\" % i)\n",
        "    for ind in sorted_order[i, :10]:\n",
        "        print (' %s' % terms[ind])\n",
        "    print"
      ],
      "metadata": {
        "id": "QhH3I0DIx7bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4dc7e36-7038-48fa-b947-450e93fb06f4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top words per cluster:\n",
            "Cluster 0:\n",
            " trump\n",
            " president\n",
            " court\n",
            " ban\n",
            " carroll\n",
            " case\n",
            " testify\n",
            " jury\n",
            " new\n",
            " federal\n",
            "Cluster 1:\n",
            " biden\n",
            " not\n",
            " people\n",
            " amp\n",
            " state\n",
            " president\n",
            " say\n",
            " child\n",
            " school\n",
            " day\n",
            "Cluster 2:\n",
            " tucker\n",
            " carlson\n",
            " fox\n",
            " vote\n",
            " life\n",
            " news\n",
            " say\n",
            " not\n",
            " like\n",
            " trump\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To reduce the dimension of Tf-Idf matrix we define error term, distance matrix using cosine similarity"
      ],
      "metadata": {
        "id": "BVaZD1nwyAEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a distance matrix by subtracting cosine similarity matrix by ones\n",
        "dist_matrix = 1 - cosine_similarity(tfidf_matrix)\n",
        "dist_matrix"
      ],
      "metadata": {
        "id": "ts1jF-jrx9kY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e46542e-6ef0-408f-abda-e498996874e6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00,  8.54063278e-01,  6.63652528e-01, ...,\n",
              "         1.00000000e+00,  8.83852287e-01,  9.90805475e-01],\n",
              "       [ 8.54063278e-01,  0.00000000e+00,  8.16171223e-01, ...,\n",
              "         1.00000000e+00,  8.98250459e-01,  8.75759179e-01],\n",
              "       [ 6.63652528e-01,  8.16171223e-01,  0.00000000e+00, ...,\n",
              "         1.00000000e+00,  6.40654194e-01,  9.05294756e-01],\n",
              "       ...,\n",
              "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
              "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [ 8.83852287e-01,  8.98250459e-01,  6.40654194e-01, ...,\n",
              "         1.00000000e+00, -2.22044605e-16,  8.83590046e-01],\n",
              "       [ 9.90805475e-01,  8.75759179e-01,  9.05294756e-01, ...,\n",
              "         1.00000000e+00,  8.83590046e-01,  0.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create unique list of names\n",
        "Uncommon_names = usersOfChannels['Clusters'].unique()\n",
        "print(Uncommon_names)\n",
        "# Create a data frame dictionary to store data frames where the keys are unique cluster labels and values are empty dataframes for now\n",
        "DataFrameDict = {elem : pd.DataFrame for elem in Uncommon_names}"
      ],
      "metadata": {
        "id": "1NkvgP3ZyG5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d507d41-93dd-4290-d6bb-20d3d4b69031"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataframe Dictionary: \" , DataFrameDict)"
      ],
      "metadata": {
        "id": "iTuqSm-NftVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "160ee0d0-bde3-4fce-e0c7-989acbdaad22"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe Dictionary:  {1: <class 'pandas.core.frame.DataFrame'>, 0: <class 'pandas.core.frame.DataFrame'>, 2: <class 'pandas.core.frame.DataFrame'>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over each cluster label\n",
        "for key in DataFrameDict.keys():\n",
        "# Assign values in the cluster label in userOfChannels to DataFrameDict\n",
        "    DataFrameDict[key] = usersOfChannels[:][usersOfChannels.Clusters == key]\n"
      ],
      "metadata": {
        "id": "fk7bgdn7yLP2"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrameDict"
      ],
      "metadata": {
        "id": "dqQHQu_DgVO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de14aaaa-7382-4ee4-a163-189d831aa1c6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1:                Users  FollowersCount  TotalTweets  \\\n",
              " 0        BootsieJazz        4.939855         8007   \n",
              " 1       unrulysoljah        1.893738       218527   \n",
              " 2      FaithTiffany2        1.093750        54665   \n",
              " 3       FrittsJensen      204.000000        24826   \n",
              " 4    AustinCCollier1        1.050483       104918   \n",
              " 5           1956kobe        3.437086       113776   \n",
              " 6          oldriccid        1.130834       110071   \n",
              " 7            PHD3535        1.094595        36553   \n",
              " 8       TheJFKReport        9.972566        52262   \n",
              " 9        AnnStokes55        1.257820       297637   \n",
              " 11     Engineerbooef       29.166667         5301   \n",
              " 12      boldlybeaded        1.106354         2924   \n",
              " 13         intell911        1.221174         2685   \n",
              " 14      jemnotgem_22        1.043236        97357   \n",
              " 17           mrddmia        4.101199        82009   \n",
              " 18    GabrielaBiniek        1.475000        41979   \n",
              " 19    commonsense258        3.715596       481102   \n",
              " 20        ryan102857        1.640681       357209   \n",
              " 22       nuez_martha        1.367243       544497   \n",
              " 23     mototanthosya        1.143901       379180   \n",
              " 24          Charliac        1.368421        26738   \n",
              " 25     martincynthia        1.125997       138404   \n",
              " 26          L_YESGAL        1.094431        75198   \n",
              " 27        kjgheroman        5.091603       382258   \n",
              " 28          cstodd72        5.250000        76966   \n",
              " 29   AustinCCollier1        1.050483       104919   \n",
              " 30        MarcMscapa        1.066667         1463   \n",
              " 32          21alonzo        8.466667       128956   \n",
              " 33   LonewolfBilly44        2.649351        13973   \n",
              " 34   TodaywithHannah      661.000000         2539   \n",
              " 37       VideSulizan        5.083333       281205   \n",
              " 38   LaCiuraRaffaele        1.397463       233376   \n",
              " 39           wsi_usa        1.226607       137653   \n",
              " 40         Atomic707        1.520408        10084   \n",
              " 41    thejendoctrine        5.118227       124765   \n",
              " 46       shantaclair        1.101338       157836   \n",
              " 51      annaliesalin        1.537440       117646   \n",
              " 58         Burnett18        1.761218         1188   \n",
              " 60       CupcakeMrs1        1.065217       369234   \n",
              " 62   zeeshan_shah_dc        8.515152       811808   \n",
              " 64      hamiltonmain        2.116711        23225   \n",
              " 68        TottenBill       35.089552       954217   \n",
              " 70      QueenStellaK        1.568075        77341   \n",
              " 72       Larry__Andy        2.730463       425216   \n",
              " 74       willybfrank        1.694274       106053   \n",
              " 75       trymainelee       21.940118        11443   \n",
              " 76    FightFakeNews4        1.000576       294267   \n",
              " 77     RyanVanVelzer        2.435744         8922   \n",
              " 80       Desinumber9        5.691667        41470   \n",
              " 84            jp1dp2        1.473214       430761   \n",
              " 86     justryin2live        1.178948        47234   \n",
              " 94          Ky71Matt        1.450000       137285   \n",
              " 95           labbarb        1.539855        58404   \n",
              " 96    FightFakeNews4        1.000288       294267   \n",
              " 97     CliftonKinnie        4.877106        29633   \n",
              " 99        MOMO198425        2.975610        10705   \n",
              " 100      SDK_Resists        1.010965       141399   \n",
              " 101        filafresh        1.642738      2806310   \n",
              " \n",
              "                                             UserTweets  \\\n",
              " 0    [Always remember that whenever a democrat says...   \n",
              " 1    [I am saddened how some gospel musicians treat...   \n",
              " 2    [Our Girl https://t.co/2gYkZ5OaHS, Senator Nan...   \n",
              " 3    [@ChasingKensho @FoxNews They are literally ta...   \n",
              " 4    [TURNING THE TABLES: The suspects chose the wr...   \n",
              " 5    [Message from our next President  https://t.co...   \n",
              " 6    ['THE COUNTRY IS WATCHING': Reporter grills Pr...   \n",
              " 7    [Democratic lawmakers caught on hot mic mockin...   \n",
              " 8    [@CivilRights Sex changes for children aren't ...   \n",
              " 9    [After four years of Biden, it’s not “Morning ...   \n",
              " 11   ['AREN'T TAKING CARE OF US': East Palestine re...   \n",
              " 12   [@TuckerCarlson Real news shows both sides.  G...   \n",
              " 13   [Surviving roommate agrees to interview with B...   \n",
              " 14   [the way rosé hits that \"i dont want YOU no mo...   \n",
              " 17   [Democratic lawmakers caught on hot mic mockin...   \n",
              " 18   [Trochę ostatnio zaczęłam  wątpić  w święteg C...   \n",
              " 19   [Snapchat AI seems a bit biased https://t.co/8...   \n",
              " 20   [“In the last days there will come times of di...   \n",
              " 22   [Ministro, sea serio: \"RENUNCIE!\"\\n\\n@mindefen...   \n",
              " 23   [@C_OkosamaLunch そりゃちょうど良かった！アボット将軍はシーズン2で活躍する...   \n",
              " 24   [The NHL has now officially shared that Friday...   \n",
              " 25   [How ironic is that the USA gives between $200...   \n",
              " 26   [Offensive line additions under Jeff Brohm:\\n4...   \n",
              " 27   [바이든 대통령은 윤석열 대통령과 지난 한 해 동안 여러 차례 만났으며, 그 때마다...   \n",
              " 28   [Knicks advance to second round of NBA playoff...   \n",
              " 29   [TURNING THE TABLES: The suspects chose the wr...   \n",
              " 30   [Good morning everyone  ... https://t.co/EqrwK...   \n",
              " 32   [In this edition of the Daily Feed with @tommc...   \n",
              " 33   [CHEAT SHEET: President Biden is no stranger t...   \n",
              " 34   [@CNNPolitics I'm willing to show 10 lucky peo...   \n",
              " 37   [\"You’re out doing those other jobs when, sudd...   \n",
              " 38   [UK regulators blocked Microsoft’s $69 billion...   \n",
              " 39   [Bankers’ pitch to save First Republic: Help u...   \n",
              " 40   [First Republic Bank, hardly a household name ...   \n",
              " 41   [@Sam80828861 Scorpion definitely surpassed 10...   \n",
              " 46   [Do you realize how bad a song has to be for e...   \n",
              " 51   [EBONY Celebrates its April Cover and Jamaica ...   \n",
              " 58   [A mother of two students in Howard City, Mich...   \n",
              " 60   [Our takeaway from the Zelensky-Xi phone call:...   \n",
              " 62   [Scoop: Businesses on Harlem's 125th Street ha...   \n",
              " 64   [Good evening https://t.co/SPrsYKWKCE, @IRISHK...   \n",
              " 68   [A 6th century Byzantine bracelet made with go...   \n",
              " 70   [- Hillary strange, Biden strange. Clinton str...   \n",
              " 72   [A suspect was arrested Tuesday after the murd...   \n",
              " 74   [When it's needed the most, Dániel Gazdag for ...   \n",
              " 75   [20 HBCUs tell the AP they have added at least...   \n",
              " 76   [More than two people in US died from guns eve...   \n",
              " 77   [In an exclusive interview with NBC News' Sava...   \n",
              " 80   [As someone who is both a father and a stepfat...   \n",
              " 84   [‘Worst Ratings Since Pre-9/11’: CNN Reporter ...   \n",
              " 86   [@letstalkshoes22 @BadBradRSR I know Florida i...   \n",
              " 94   [\"A Ray of Hope\"\\nWeek of August 2 - August 6,...   \n",
              " 95   [@NewMutant In all honesty they look exactly t...   \n",
              " 96   [More than two people in US died from guns eve...   \n",
              " 97   [These four House Republicans voted against th...   \n",
              " 99   [@laomanshujuku 好像还有福建, 更正：：理论上央行可以追踪数字货币（不是现金...   \n",
              " 100  [Speaker McCarthy’s debt limit proposal would ...   \n",
              " 101  [Minute Maid &gt; Tropicana\\n\\nFinal: #Astros ...   \n",
              " \n",
              "                                                ptweets  Clusters  \n",
              " 0    remember democrat say exact opposite true ford...         1  \n",
              " 1    gospel musician treat house god justifies not ...         1  \n",
              " 2    girl senator nancy schaefer wages war child pr...         1  \n",
              " 3    literally target disabled child dutch governme...         1  \n",
              " 4    turn table suspect choose wrong home invade kn...         1  \n",
              " 5    message president miss can not wait suspect te...         1  \n",
              " 6    country watch reporter grill president biden c...         1  \n",
              " 7    democratic lawmaker catch hot mic mock parenta...         1  \n",
              " 8    sex change child not critical medically necess...         1  \n",
              " 9    year biden morning america america mourning te...         1  \n",
              " 11   not take care east palestine resident courtney...         1  \n",
              " 12   real news show side glad leave act like massiv...         1  \n",
              " 13   survive roommate agree interview bryan defense...         1  \n",
              " 14   way hit not want good vocalist reason turn tab...         1  \n",
              " 17   democratic lawmaker catch hot mic mock parenta...         1  \n",
              " 18   jak randi weingarten say biden transition team...         1  \n",
              " 19   bit bias remain wild real thing happen walker ...         1  \n",
              " 20   day come time difficulty people lover self lov...         1  \n",
              " 22   sea que sin haber del actual hay hay hoy bien ...         1  \n",
              " 23   427 open hope video red panda eat make day wel...         1  \n",
              " 24   nhl officially share friday game ubs arena can...         1  \n",
              " 25   ironic usa give 200 amp 600 million year femal...         1  \n",
              " 26   offensive line addition jeff madden 305 luke b...         1  \n",
              " 27   finally strong lord mighty power 610 ask fathe...         1  \n",
              " 28   advance second round nba playoff time year not...         1  \n",
              " 29   turn table suspect choose wrong home invade kn...         1  \n",
              " 30   good morning gop bill repeal biden policy forc...         1  \n",
              " 32   edition daily feed kevin mccarthy put ball joe...         1  \n",
              " 33   cheat sheet president biden stranger detailed ...         1  \n",
              " 34   willing lucky people earn daily withdrawal fee...         1  \n",
              " 37   you ’re job suddenly you ’re matter people peo...         1  \n",
              " 38   regulator block microsoft billion purchase bli...         1  \n",
              " 39   banker pitch save republic help pay later fail...         1  \n",
              " 40   republic bank hardly household month concern i...         1  \n",
              " 41   scorpion definitely surpass 100 ticket sale su...         1  \n",
              " 46   realize bad song suck way room gag extinct mon...         1  \n",
              " 51   celebrates april cover jamaica carnival huge b...         1  \n",
              " 58   mother student howard city michigan file lawsu...         1  \n",
              " 60   phone demonstrate beijing want involve militar...         1  \n",
              " 62   scoop business harlem street file lawsuit stop...         1  \n",
              " 64   good evening prefer term borrow will not open ...         1  \n",
              " 68   6th century byzantine bracelet gold silver set...         1  \n",
              " 70   hillary strange biden strange clinton strange ...         1  \n",
              " 72   suspect arrest tuesday murder eat driver alleg...         1  \n",
              " 74   need make mistake spot important game get slop...         1  \n",
              " 75   tell add ncaa championship emerge sport 2016 i...         1  \n",
              " 76   people die gun hour god look miserably unhappy...         1  \n",
              " 77   exclusive interview nbc news savannah parent g...         1  \n",
              " 80   father like tell kiss ample ass tell secret tr...         1  \n",
              " 84   bad rating cnn reporter say fox news viewershi...         1  \n",
              " 86   know florida awful politically trust indiana b...         1  \n",
              " 94   ray hope week august august 1965 ray hope week...         1  \n",
              " 95   honesty look exactly juan say wait police offi...         1  \n",
              " 96   people die gun hour god look miserably unhappy...         1  \n",
              " 97   house republicans vote gop debt limit bill man...         1  \n",
              " 99                                                             1  \n",
              " 100  speaker mccarthy debt limit proposal wreck eco...         1  \n",
              " 101  minute maid tropicana final rays happen that l...         1  ,\n",
              " 0:               Users  FollowersCount  TotalTweets  \\\n",
              " 10  FerdinandMunoz9        1.133333         9359   \n",
              " 15         corrcomm        1.570466       468255   \n",
              " 47    sosprachmarsu        1.980817       148897   \n",
              " 61       RoxanaSato        1.151386       181043   \n",
              " 63   Pupito47Rafael        1.755319        34100   \n",
              " 66  SerendipitySays        6.527933      1501749   \n",
              " 71          nuochan        1.367642       104874   \n",
              " 73    straitarrow10        4.475735       927860   \n",
              " 78  lakegenevascott        1.110665        40219   \n",
              " 82        maggisays        1.839080        58204   \n",
              " 83  KhemSin35053428       29.000000         1192   \n",
              " 85      mark_lawler        1.521739        67005   \n",
              " 87      Morning_Joe     1216.041270        65782   \n",
              " 88  VFlowingFineArt        1.001272        97439   \n",
              " 90        geoff9cow        1.552936       397264   \n",
              " 93       yvonnezipp        1.298701        22154   \n",
              " 98         yeskyyes       41.449612        14948   \n",
              " \n",
              "                                            UserTweets  \\\n",
              " 10  [Freshpet Dinner Date Commercial | :30 https:/...   \n",
              " 15  [@free_mind2019 @FoxNews What “nonsense”?, TUR...   \n",
              " 47  [Pras Michel, a founding member of the group t...   \n",
              " 61  [Further evidence of Russian genocide in Ukrai...   \n",
              " 63  [Details here\\nhttps://t.co/69TElGX2uy, NEWS 🚨...   \n",
              " 66  [From @FaceTheNation on Sunday https://t.co/9g...   \n",
              " 71  [Try to find anyone who enjoys relaxing in the...   \n",
              " 73  [Yep.  https://t.co/ian1LBNHLA, If you confess...   \n",
              " 78  [Breaking news: Donald Trump cannot block his ...   \n",
              " 82  [Dear E. Jean Carroll:\\n\\nTrump only lashes ou...   \n",
              " 83  [🇮🇳Curtain raiser of #adscoin itself is going ...   \n",
              " 85  [🚨🚨🚨BREAKING: Smartmatic WINS its first major ...   \n",
              " 87  [\"I don't believe this is about stopping Trump...   \n",
              " 88  [We must repeal Wisconsin's 1800s-era criminal...   \n",
              " 90  [@spottygp @LiftForever67 .\\n#Utah Hunting Gui...   \n",
              " 93  [NEW on @axios: The top brass at  @wsj @washin...   \n",
              " 98  [High-Tech Neocannibalism\\n高科技新食人主义 https://t....   \n",
              " \n",
              "                                               ptweets  Clusters  \n",
              " 10  dinner date commercial not pet long find hilar...         0  \n",
              " 15  nonsense turn table suspect choose wrong home ...         0  \n",
              " 47  michel found member group find guilty internat...         0  \n",
              " 61  evidence russian genocide ukraine biden age tr...         0  \n",
              " 63  detail news europe launches juice spacecraft s...         0  \n",
              " 66  sunday break news donald trump block vice pres...         0  \n",
              " 71  try find enjoy relax sun young elephant seal t...         0  \n",
              " 73  yep confess crime crime arrest rudy giuliani u...         0  \n",
              " 78  break news donald trump block vice president t...         0  \n",
              " 82  dear jean carroll trump lash afraid make perso...         0  \n",
              " 83  curtain raiser big bang world community get re...         0  \n",
              " 85  break win major legal battle fox news turn add...         0  \n",
              " 87  not believe stop trump continue pursuit prefer...         0  \n",
              " 88  repeal wisconsin criminal abortion ban restore...         0  \n",
              " 90  utah hunting guide face felony baiting bear ki...         0  \n",
              " 93  new brass run joint letter color paper tomorro...         0  \n",
              " 98  break argentina announce pay chinese import yu...         0  ,\n",
              " 2:               Users  FollowersCount  TotalTweets  \\\n",
              " 16    Victoriaokane        1.342234       320762   \n",
              " 21    nmlinguaphile        6.549302       130744   \n",
              " 31     jannyzeeland        1.293499       417545   \n",
              " 35      Nitegammer_       11.500000       144165   \n",
              " 36  deduped_nytimes      325.000000       262870   \n",
              " 42         iu22ie33       92.686441         8147   \n",
              " 43      emeraldbesi        1.045249        86819   \n",
              " 44    datGheeChiGul        2.480000       345129   \n",
              " 45        lmisitzis       11.945634         5372   \n",
              " 48        laolu_dee        1.317043       283025   \n",
              " 49         BSBonner        2.062591       171900   \n",
              " 50       GHiggins18        3.626263        24388   \n",
              " 52       guidegroup        4.420168        21512   \n",
              " 53          jodas11        2.459770       319981   \n",
              " 54          bjppx77        2.045455        14031   \n",
              " 55         Troy_IRL       28.600000        19624   \n",
              " 56         Deb_Tiva        2.607032       410982   \n",
              " 57  PeerPressurDoIt        1.038105       100102   \n",
              " 59  catlove71040608        1.802673       162853   \n",
              " 65          RJCass1        1.062044        29915   \n",
              " 67      L_sanchez35        1.015717        31230   \n",
              " 69       VivaRevolt        1.283525       300122   \n",
              " 79      ann_resists        1.044417        93052   \n",
              " 81     PugglemanDrg        1.060914        25151   \n",
              " 89           xhertx        1.550204       461737   \n",
              " 91       stevenromo       41.443883        20060   \n",
              " 92    fastnewsfacts       24.161290          344   \n",
              " \n",
              "                                            UserTweets  \\\n",
              " 16  [REPORT: DeSantis Jumping in 2024 Presidential...   \n",
              " 21  [The DOJ is adamant that children who survive ...   \n",
              " 31  [@MinisterKenE Desinformatie. Er is geen klima...   \n",
              " 35  [Prisoner swap?!?!? this is how bad the CCP wa...   \n",
              " 36  [The writer E. Jean Carroll took the witness s...   \n",
              " 42  [My daughter recently got married. One of the ...   \n",
              " 43  [If every billionaire was more like Elon Musk ...   \n",
              " 44  [Roy Wood Jr. talks all things WHCD: ‘There wi...   \n",
              " 45  [My daughter recently got married. One of the ...   \n",
              " 48  [The workouts you don't feel like doing are th...   \n",
              " 49  [***BREAKING***\\n\\nReportedly, there have been...   \n",
              " 50  [Rainfall level expected to increase in May - ...   \n",
              " 52  [@susieorr56 GREAT news!, a year ago @VP was t...   \n",
              " 53  [Invito a mis paisanos a ver Circombia con @Da...   \n",
              " 54  [【美国前国安顾问博尔顿26日抵达台湾】\\n【访台期间将有至少2场演说】\\n美国前国家安全顾...   \n",
              " 55  [@RadioFreeTom He’s speaking to a narrow audie...   \n",
              " 56  [Kevin McCarthy's Special Committee is attacki...   \n",
              " 57  [female therapist: your friend with a fat ugly...   \n",
              " 59  [I’m still recovering from last week’s cancer ...   \n",
              " 65  [They have a new outrage. Barbie with Downs Sy...   \n",
              " 67  [CNN's @oliverdarcy reports that Fox News expe...   \n",
              " 69  [NEW on @axios: The top brass at  @wsj @washin...   \n",
              " 79  [This is a plea that Republicans shouldn’t vot...   \n",
              " 81  [🇺🇸 Donald J. Trump on \"Ross Perot\"\\n🎙️Letterm...   \n",
              " 89  [Read @Ripleys Daily CARTOON 04-26-2023 https:...   \n",
              " 91  [@25thCenturyTrek @StephenMorganTV Very much s...   \n",
              " 92  [2023 NFL draft: Who will Chargers pick first?...   \n",
              " \n",
              "                                               ptweets  Clusters  \n",
              " 16  jump presidential race day tucker fire fox new...         2  \n",
              " 21  adamant child survive abortion music class cut...         2  \n",
              " 31  heel economie kan burger het imagine world cla...         2  \n",
              " 35  prisoner swap bad ccp want miles guo bad watch...         2  \n",
              " 36  writer jean carroll take witness stand tell ma...         2  \n",
              " 42  daughter recently get marry guest invite frien...         2  \n",
              " 43  billionaire like elon musk like bill gate worl...         2  \n",
              " 44  roy wood talk thing there clarence thomas joke...         2  \n",
              " 45  daughter recently get marry guest invite frien...         2  \n",
              " 48  workout not feel like one need grandma die dyn...         2  \n",
              " 49  break reportedly explosion aviation repair pla...         2  \n",
              " 50  rainfall level expect increase meet office pro...         2  \n",
              " 52  great news year ago talk freedom work work sin...         2  \n",
              " 53  mis ver con que petro con los con los judicial...         2  \n",
              " 54  world happiness report low rank country 122 12...         2  \n",
              " 55  speak narrow audience understand tucker carlso...         2  \n",
              " 56  kevin special committee attack teacher union t...         2  \n",
              " 57  female therapist friend fat ugly baby accept t...         2  \n",
              " 59  recover week cancer treatment capitol vote rep...         2  \n",
              " 65  new outrage barbie downs syndrome abortion med...         2  \n",
              " 67  report fox news experience low rating septembe...         2  \n",
              " 69  new brass run joint letter color paper tomorro...         2  \n",
              " 79  plea republicans should not vote make differen...         2  \n",
              " 81  donald trump ross 1992 remember democrats medi...         2  \n",
              " 89  read daily watch produce look inside million d...         2  \n",
              " 91  mirror mirror wall unexpectedly scary pedro we...         2  \n",
              " 92  2023 nfl draft charger pick depth 21st choice ...         2  }"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries for sentiment analysis\n",
        "from textblob import TextBlob\n",
        "from textblob.sentiments import NaiveBayesAnalyzer"
      ],
      "metadata": {
        "id": "MHby8lcfyMdv"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize two dictionaries with uniquenames as keys \n",
        "polaritycluster={elem : pd.DataFrame for elem in Uncommon_names}\n",
        "subjectivitycluster={elem : pd.DataFrame for elem in Uncommon_names}\n",
        "# Iterate over DataFrameDict for each key\n",
        "for i in DataFrameDict.keys():\n",
        "# Join all tweets into a string and returning Textblob object\n",
        "# Calculate polarity and subjectivity of all tweets in the dataframe\n",
        "    polaritycluster[i]=TextBlob(' '.join(DataFrameDict[i]['UserTweets'].astype('str'))).sentiment.polarity\n",
        "    subjectivitycluster[i]=TextBlob(' '.join(DataFrameDict[i]['UserTweets'].astype('str'))).sentiment.subjectivity\n",
        "# sentiment.polarity - retruns polarity score from -1 to 1\n",
        "# sentiment.subjectivity - returns subjectivity score from 0 to 1"
      ],
      "metadata": {
        "id": "avE2zMCKyNqK"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "polaritycluster"
      ],
      "metadata": {
        "id": "D2xW080RyOsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0f20fa-efe0-4608-e369-dc7c8c9ced3c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 0.06880078595314833, 0: 0.11615838508475312, 2: 0.08377821063631269}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subjectivitycluster"
      ],
      "metadata": {
        "id": "FAwV7lz4yQk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1c631a-c97d-41d6-a099-ccd088a41bff"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 0.4652149839350785, 0: 0.4681229291690665, 2: 0.4402055801564223}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web scraping and corpus building"
      ],
      "metadata": {
        "id": "rpEqxCHJ_fcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access and modify localization setting of the system\n",
        "import locale\n",
        "print(locale.getpreferredencoding())"
      ],
      "metadata": {
        "id": "6CYVhLcsySLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d06ec67-8e27-4ccf-ba11-6eb26f997cfd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UTF-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defination for return UTF-8 encoding\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "WswyfDyeyT2x"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing newspaper3k package and import article library\n",
        "import newspaper\n",
        "from newspaper import Article\n",
        "\n",
        "# For similarity measure\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "CqXLh8i-yXLH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import statements for corpus\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import newspaper\n",
        "import pandas as pd\n",
        "\n",
        "# URL of the news papers\n",
        "\n",
        "bbc_paper = 'https://www.bbc.com/'\n",
        "cnn_paper='https://edition.cnn.com/'\n",
        "wp_paper = 'https://washingtonpost.com'\n",
        "# Make a request to the website and get the HTML content\n",
        "\n",
        "# bbc Post:\n",
        "bbc_response = requests.get(bbc_paper)\n",
        "bbc_html_content = bbc_response.content\n",
        "\n",
        "# CNN:\n",
        "cnn_response = requests.get(cnn_paper)\n",
        "cnn_html_content = cnn_response.content\n",
        "\n",
        "# wp:\n",
        "wp_response = requests.get(wp_paper)\n",
        "wp_html_content = wp_response.content\n",
        "\n",
        "# Use BeautifulSoup to parse the HTML content\n",
        "bbc_soup = BeautifulSoup(bbc_html_content, 'html.parser')\n",
        "cnn_soup = BeautifulSoup(cnn_html_content, 'html.parser')\n",
        "wp_soup = BeautifulSoup(wp_html_content, 'html.parser')\n",
        "\n",
        "# Find all the links on the page\n",
        "bbc_links = bbc_soup.find_all('a')\n",
        "cnn_links = cnn_soup.find_all('a')\n",
        "wp_links = wp_soup.find_all('a')\n",
        "\n",
        "\n",
        "# The more the links and the larger the corpus the better and more specific the more precise the recommendation will be\n",
        "\n",
        "\n",
        "# Filter the links to only include articles from the Washington Post\n",
        "bb_links = [link for link in bbc_links if 'www.bbc.com' in link.get('href', '')]\n",
        "cn_links = [link for link in cnn_links if 'edition.cnn.com' in link.get('href','')]\n",
        "wp_links = [link for link in wp_links if 'www.washingtonpost.com' in link.get('href','')]\n",
        "\n",
        "# Create a list to hold the article data\n",
        "article_data = []\n",
        "\n",
        "# Loop through the links and get the article text and link for each one\n",
        "for link in bb_links:\n",
        "    # Use newspaper to download and parse the article\n",
        "    article = newspaper.Article(link['href'])\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    \n",
        "    # Add the article data to the list\n",
        "    article_data.append({\n",
        "        'link': link['href'],\n",
        "        'text': article.text\n",
        "    })\n",
        "\n",
        "# cnn\n",
        "for link in cn_links:\n",
        "    # Use newspaper to download and parse the article\n",
        "    article = newspaper.Article(link['href'])\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    \n",
        "    # Add the article data to the list\n",
        "    article_data.append({\n",
        "        'link': link['href'],\n",
        "        'text': article.text\n",
        "    })\n",
        "\n",
        "# wp\n",
        "for link in wp_links:\n",
        "    # Use newspaper to download and parse the article\n",
        "    article = newspaper.Article(link['href'])\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    \n",
        "    # Add the article data to the list\n",
        "    article_data.append({\n",
        "        'link': link['href'],\n",
        "        'text': article.text\n",
        "    })\n",
        "\n",
        "# Create a Pandas DataFrame from the article data\n",
        "df = pd.DataFrame(article_data)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "RgW6Eo4sydLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50757be4-7cc1-4482-dc6d-e7d74fe72aec"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  link  \\\n",
            "0                                 https://www.bbc.com/   \n",
            "1                             https://www.bbc.com/news   \n",
            "2                            https://www.bbc.com/sport   \n",
            "3                             https://www.bbc.com/reel   \n",
            "4                         https://www.bbc.com/worklife   \n",
            "..                                                 ...   \n",
            "507                     https://www.washingtonpost.com   \n",
            "508     https://www.washingtonpost.com/about-the-post/   \n",
            "509  https://www.washingtonpost.com/anonymous-news-...   \n",
            "510  https://www.washingtonpost.com/discussions/202...   \n",
            "511      https://www.washingtonpost.com/cookie-policy/   \n",
            "\n",
            "                                                  text  \n",
            "0    Pep Guardiola says Manchester City are deliver...  \n",
            "1    Trump rape accuser E Jean Carroll takes the st...  \n",
            "2    The Ironman unbroken by a bomb\\n\\nLosing blood...  \n",
            "3               Why your life is probably a simulation  \n",
            "4                                         How we think  \n",
            "..                                                 ...  \n",
            "507  Speaker Kevin McCarthy (R-Calif.) aims to forc...  \n",
            "508  The first mission of a newspaper is to tell th...  \n",
            "509  The Washington Post offers several ways to sec...  \n",
            "510  As a global leader in media as well as SaaS fo...  \n",
            "511  Ask the Post Cookie Notice\\n\\nShare\\n\\nUpdated...  \n",
            "\n",
            "[512 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#   Dropping the duplicate links from the dataframe\n",
        "df.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "3Uv3DI_0S7_d"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe containing data extracted from the different news channles\n",
        "df"
      ],
      "metadata": {
        "id": "lT018zSRTNMN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a9b937c6-7571-463d-9ad9-6c87a083868c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  link  \\\n",
              "0                                 https://www.bbc.com/   \n",
              "1                             https://www.bbc.com/news   \n",
              "2                            https://www.bbc.com/sport   \n",
              "3                             https://www.bbc.com/reel   \n",
              "4                         https://www.bbc.com/worklife   \n",
              "..                                                 ...   \n",
              "502     https://www.washingtonpost.com/privacy-policy/   \n",
              "503      https://www.washingtonpost.com/cookie-policy/   \n",
              "504  https://www.washingtonpost.com/discussions/202...   \n",
              "505  https://www.washingtonpost.com/information/202...   \n",
              "506                     https://www.washingtonpost.com   \n",
              "\n",
              "                                                  text  \n",
              "0    Pep Guardiola says Manchester City are deliver...  \n",
              "1    Trump rape accuser E Jean Carroll takes the st...  \n",
              "2    The Ironman unbroken by a bomb\\n\\nLosing blood...  \n",
              "3               Why your life is probably a simulation  \n",
              "4                                         How we think  \n",
              "..                                                 ...  \n",
              "502  Site Information Privacy Policy\\n\\nShare\\n\\nPu...  \n",
              "503  Ask the Post Cookie Notice\\n\\nShare\\n\\nUpdated...  \n",
              "504  Site Information RSS Terms of Service\\n\\nShare...  \n",
              "505  Site Information Ad choices\\n\\nShare\\n\\nPublis...  \n",
              "506  Speaker Kevin McCarthy (R-Calif.) aims to forc...  \n",
              "\n",
              "[316 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec839674-8fe1-42e5-aeff-445e654268fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.bbc.com/</td>\n",
              "      <td>Pep Guardiola says Manchester City are deliver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.bbc.com/news</td>\n",
              "      <td>Trump rape accuser E Jean Carroll takes the st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.bbc.com/sport</td>\n",
              "      <td>The Ironman unbroken by a bomb\\n\\nLosing blood...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.bbc.com/reel</td>\n",
              "      <td>Why your life is probably a simulation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.bbc.com/worklife</td>\n",
              "      <td>How we think</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>https://www.washingtonpost.com/privacy-policy/</td>\n",
              "      <td>Site Information Privacy Policy\\n\\nShare\\n\\nPu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>https://www.washingtonpost.com/cookie-policy/</td>\n",
              "      <td>Ask the Post Cookie Notice\\n\\nShare\\n\\nUpdated...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>https://www.washingtonpost.com/discussions/202...</td>\n",
              "      <td>Site Information RSS Terms of Service\\n\\nShare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>https://www.washingtonpost.com/information/202...</td>\n",
              "      <td>Site Information Ad choices\\n\\nShare\\n\\nPublis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>https://www.washingtonpost.com</td>\n",
              "      <td>Speaker Kevin McCarthy (R-Calif.) aims to forc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>316 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec839674-8fe1-42e5-aeff-445e654268fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec839674-8fe1-42e5-aeff-445e654268fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec839674-8fe1-42e5-aeff-445e654268fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing of the articles and the texts to for further processing"
      ],
      "metadata": {
        "id": "EcUAwv2nSUxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def processArticles(articles):\n",
        "  #cleaning of articles\n",
        "  cleanedarticles = []\n",
        "  for article in articles: \n",
        "      article = re.sub(\"[^a-zA-Z]\",\" \", str(article))\n",
        "      article = article.lower() # Converting to lowercase letters\n",
        "      article = ' '.join([word for word in article.split() if word not in (stop)]) # Removing stop words\n",
        "      article = ' '.join([word for word in article.split() if len(word)>2])   \n",
        "\n",
        "      # Tokenization\n",
        "      article = nlp(article) \n",
        "\n",
        "      # Stemming (lemmatization in spacy)\n",
        "      article = [token.lemma_ for token in article]\n",
        "\n",
        "      # Remove small and unnecessary words\n",
        "      article = [word for word in article if len(word)>2]\n",
        "      article = ' '.join(w for w in article if w in words)\n",
        "\n",
        "      cleanedarticles.append(article)\n",
        "#  Return the processed article text\n",
        "  return cleanedarticles"
      ],
      "metadata": {
        "id": "Y9D5YHoiyfg8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = processArticles(df['text'])"
      ],
      "metadata": {
        "id": "LIOqR3B1zRAY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The dataframe is a corpus of the web scrapped data and will be further used in recommendation system and similarity matching\n",
        "df"
      ],
      "metadata": {
        "id": "P3YHa-UzSRpb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b3ef710e-17a6-49d4-e8c1-2541ca02d322"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  link  \\\n",
              "0                                 https://www.bbc.com/   \n",
              "1                             https://www.bbc.com/news   \n",
              "2                            https://www.bbc.com/sport   \n",
              "3                             https://www.bbc.com/reel   \n",
              "4                         https://www.bbc.com/worklife   \n",
              "..                                                 ...   \n",
              "502     https://www.washingtonpost.com/privacy-policy/   \n",
              "503      https://www.washingtonpost.com/cookie-policy/   \n",
              "504  https://www.washingtonpost.com/discussions/202...   \n",
              "505  https://www.washingtonpost.com/information/202...   \n",
              "506                     https://www.washingtonpost.com   \n",
              "\n",
              "                                                  text  \n",
              "0    pep say manchester city delivering option win ...  \n",
              "1    trump rape accuser jean carroll take stand emo...  \n",
              "2    unbroken bomb lose blood run low time know cho...  \n",
              "3                             life probably simulation  \n",
              "4                                                think  \n",
              "..                                                 ...  \n",
              "502  site information privacy policy share publish ...  \n",
              "503  ask post cookie notice share update february c...  \n",
              "504  site information term service share encourage ...  \n",
              "505  site information choice share publish septembe...  \n",
              "506  speaker kevin mccarthy calif aim force talk wh...  \n",
              "\n",
              "[316 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-047d0366-a575-42b0-85b5-fdacf61476c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.bbc.com/</td>\n",
              "      <td>pep say manchester city delivering option win ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.bbc.com/news</td>\n",
              "      <td>trump rape accuser jean carroll take stand emo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.bbc.com/sport</td>\n",
              "      <td>unbroken bomb lose blood run low time know cho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.bbc.com/reel</td>\n",
              "      <td>life probably simulation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.bbc.com/worklife</td>\n",
              "      <td>think</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>https://www.washingtonpost.com/privacy-policy/</td>\n",
              "      <td>site information privacy policy share publish ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>https://www.washingtonpost.com/cookie-policy/</td>\n",
              "      <td>ask post cookie notice share update february c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>https://www.washingtonpost.com/discussions/202...</td>\n",
              "      <td>site information term service share encourage ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>https://www.washingtonpost.com/information/202...</td>\n",
              "      <td>site information choice share publish septembe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>https://www.washingtonpost.com</td>\n",
              "      <td>speaker kevin mccarthy calif aim force talk wh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>316 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-047d0366-a575-42b0-85b5-fdacf61476c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-047d0366-a575-42b0-85b5-fdacf61476c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-047d0366-a575-42b0-85b5-fdacf61476c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "YkqSg4R3_xPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing sentiment analysis of a users tweets to understand his positive, negative and netural sentiments towards different topics in the tweets"
      ],
      "metadata": {
        "id": "NAU9dAhNcu8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the latest tweets and retweets of a user for news using pagination which helps in retriving more than 200 tweets per user in batches or pages\n",
        "\n",
        "# function to fetch tweets and retweets\n",
        "def fetchTweets(user, count=1000):\n",
        "    all_tweets = []\n",
        "    max_id = None\n",
        "    while True:\n",
        "        # Fetch the latest batch of tweets using the max_id parameter\n",
        "        usertweets = api.user_timeline(screen_name=user, count=count, tweet_mode='extended', max_id=max_id)\n",
        "        if len(usertweets) == 0:\n",
        "            break\n",
        "        all_tweets.extend(usertweets)\n",
        "        max_id = usertweets[-1].id - 1\n",
        "    # Retweets filtering \n",
        "    toptweets = [tweet.retweeted_status.full_text if tweet.full_text.startswith(\"RT @\") else tweet.full_text for tweet in all_tweets]\n",
        "    return all_tweets\n"
      ],
      "metadata": {
        "id": "s5EBeNyhphtU"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing the tweets in twes list fo the top contributor user in our news users channel dataframe\n",
        "twes = fetchTweets(str(usersOfChannels['Users'][1]))"
      ],
      "metadata": {
        "id": "53OsfMeehLtM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of tweets retrieved of the user handle\n",
        "len(twes)"
      ],
      "metadata": {
        "id": "5g31awTq4zSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "723d9b55-997f-4bc6-dc12-f9cfea6d2c14"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3250"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the emoji library\n",
        "import emoji\n",
        "\n",
        "# Define a function to check if a tweet contains an emoji\n",
        "def contains_emoji(tweet):\n",
        "    for character in tweet:\n",
        "        if character in emoji.EMOJI_DATA:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "new = []\n",
        "# Filter the tweets to remove the ones with only the emoji text for better processing of the data during sentiment analysis\n",
        "for item in twes:\n",
        "    if isinstance(item.full_text, str) and contains_emoji(item.full_text) == False:\n",
        "        # The full_text attribute is a string\n",
        "        new.append([item.full_text])\n"
      ],
      "metadata": {
        "id": "STJptjm6ir6e"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of tweets after removing non text tweets\n",
        "len(new)"
      ],
      "metadata": {
        "id": "W8Fiscpi4miZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2be885-f560-43dd-cdba-13b79d551ae3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1786"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for preprocessing of the tweet text\n",
        "def preprocess_text(tweet):\n",
        "    # Cleaning of tweets\n",
        "    cleanedData = []\n",
        "    tweet = re.sub('http\\S+', '', tweet) # Remove links\n",
        "    tweet = re.sub('RT', '', tweet) # Remove RT of retweet\n",
        "    tweet = re.sub('@[^\\s]+','',tweet) # Remove usernames \n",
        "    tweet = \"\".join([char for char in tweet if char not in string.punctuation]) # Remove punctuations\n",
        "    tweet = tweet.lower() # Converte to lowercase letters\n",
        "    tweet = ' '.join([word for word in tweet.split() if word not in (stop)]) # Removing stop words\n",
        "    tweet = ' '.join([word for word in tweet.split() if len(word)>2]) #  Removes any word which has less than 2 letters in it\n",
        "\n",
        "    # # Tokenization\n",
        "    # processedTweets = nlp(tweet) \n",
        "\n",
        "    # # Stemming (lemmatization in spacy)\n",
        "    # processedTweets = [token.lemma_ for token in processedTweets]  # Applying the lemmetization\n",
        "\n",
        "    # processedTweets = [word for word in processedTweets if len(word)>2] # Filter out the words which has less than 2 letters in it\n",
        "\n",
        "    # processedTweets = ' '.join(w for w in processedTweets if w in words) # Filter out the words which are not present in the spacy vocabulary\n",
        "\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "JWl24aD1-red"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform sentiment analysis using VADER lexicon library and using hybrid deep neural network ANN-LSTM model to train, fit, test and evaluate the performance of our classification model"
      ],
      "metadata": {
        "id": "JtOsmJqtdLu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Imports for neural network and lstm and sentiment analyzer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, LSTM, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "df1 = pd.DataFrame(new, columns=['text'])\n",
        "df1['ptext'] = None\n",
        "# Preprocess the tweet text\n",
        "for i,text in enumerate(df1['text']):\n",
        "  df1['ptext'][i] = preprocess_text(text)\n",
        "for i,t in enumerate(df1['ptext']):\n",
        "  if len(t) == 0:\n",
        "    df1['ptext'][i] = \"world news\"\n",
        "\n",
        "# VADER lexicon sentiment analyzer library to caluclate the polarity of the sentiment\n",
        "nltk.download('vader_lexicon')\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "df1['sia_sentiment'] = df1['ptext'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
        "\n",
        "# Assign binary labels based on threshold value of the polarity\n",
        "df1['sia_sentiment_labels'] = df1['sia_sentiment'].apply(lambda x: 1 if x >= 0.7 else 0)\n",
        "\n",
        "# Encode the target variable\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df1['sia_sentiment_labels'])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df1['ptext'], y, test_size=0.2, random_state=10)\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad the sequences to the same length\n",
        "max_len = 50\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "kernel_size = 3\n",
        "filters = 250\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000, 128, input_length=max_len))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and use early stop for the process to stop from running for a long time loop and call back \n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "id": "uodPnV8qOudJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6673825-bccb-4b5e-a36d-5e7cab816eca"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "36/36 [==============================] - 8s 135ms/step - loss: 0.3072 - accuracy: 0.9264 - val_loss: 0.2041 - val_accuracy: 0.9476\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 7s 188ms/step - loss: 0.2255 - accuracy: 0.9431 - val_loss: 0.2006 - val_accuracy: 0.9476\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 0.1930 - accuracy: 0.9431 - val_loss: 0.1903 - val_accuracy: 0.9476\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 0.0795 - accuracy: 0.9772 - val_loss: 0.2156 - val_accuracy: 0.9476\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0256 - accuracy: 0.9930 - val_loss: 0.2504 - val_accuracy: 0.9476\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 4s 115ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.2527 - val_accuracy: 0.9371\n",
            "Epoch 6: early stopping\n",
            "Test loss: 0.22072049975395203\n",
            "Test accuracy: 0.9441340565681458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the test accuracy of the classification model is 0.95, which is very high implying that the VADER lexicon analyzer has a good accuracy in sentiment polarity prediction"
      ],
      "metadata": {
        "id": "t1CuGNofe13o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the duplicate links\n",
        "df1.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "9rrxv3HkTgwk"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation system using sentiment analysis results"
      ],
      "metadata": {
        "id": "p8TpYQY7_9ov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the sentiments of the users tweets now we will collect the tweets with the positive sentiment and recommend the users articles form the web scraped corpus to pertain the interest of the user in reading more of the articles and engage them on the social media platform or gain increment in product sales"
      ],
      "metadata": {
        "id": "xgpThqYZg_A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Reset the index of the dataframe to remove missing values after sentiment analysis\n",
        "df1 = df1.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "4gp5pPpJ5XS-"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect the preprocesses positve tweets for VADER analyzer\n",
        "sent_recom_preprocessed_tweets = []\n",
        "for t in range(len(df1)):\n",
        "  if df1['sia_sentiment_labels'][t] == 1:\n",
        "    sent_recom_preprocessed_tweets.append(df1['ptext'][t])\n",
        "\n",
        "\n",
        "\n",
        "# Find similar articles\n",
        "# Import tfidf vectorizer and cosine similarity library\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Use TF-IDF vectorizer to transform article text and preprocessed tweets into feature vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "# Fit transform corpus text\n",
        "article_features = vectorizer.fit_transform(df['text'])\n",
        "# Fit transorm VADER text\n",
        "sent_recom_tweet_features = vectorizer.transform(sent_recom_preprocessed_tweets)\n",
        "\n",
        "\n",
        "# Compute cosine similarities between tweet features and article features\n",
        "sent_recom_similarities = cosine_similarity(sent_recom_tweet_features, article_features)\n",
        "\n",
        "# Get indices of top 200 articles most similar to the user's tweets\n",
        "sent_recom_top_article_indices = sent_recom_similarities.mean(axis=0).argsort()[::-1][:246]\n",
        "\n",
        "\n",
        "# Get recommended articles\n",
        "sentiment_recommended_user_articles = df.iloc[sent_recom_top_article_indices][['text', 'link']]\n"
      ],
      "metadata": {
        "id": "JNSR7S3oNqdB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top recommended articles and links for the user based on sentiment polarity\n",
        "sentiment_recommended_user_articles[:10]"
      ],
      "metadata": {
        "id": "w1gZGC0izzlv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "9b9d5fcf-fac3-445f-fe5a-3e25c2ef9130"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  \\\n",
              "118  listen min comment story comment gift article ...   \n",
              "231  listen min comment story comment gift article ...   \n",
              "358  listen min comment story comment gift article ...   \n",
              "115  listen min comment story comment gift article ...   \n",
              "200  listen min comment story comment gift article ...   \n",
              "246  listen min comment story comment gift article ...   \n",
              "93   listen min comment story comment gift article ...   \n",
              "253  listen min comment story comment gift article ...   \n",
              "0    pep say manchester city delivering option win ...   \n",
              "111  listen min comment story comment gift article ...   \n",
              "\n",
              "                                                  link  \n",
              "118  https://www.washingtonpost.com/opinions/2023/0...  \n",
              "231  https://www.washingtonpost.com/politics/2023/0...  \n",
              "358  https://www.washingtonpost.com/sports/2023/04/...  \n",
              "115  https://www.washingtonpost.com/opinions/2023/0...  \n",
              "200  https://www.washingtonpost.com/politics/2023/0...  \n",
              "246  https://www.washingtonpost.com/advice/2023/04/...  \n",
              "93   https://www.washingtonpost.com/business/2023/0...  \n",
              "253  https://www.washingtonpost.com/technology/2023...  \n",
              "0                                 https://www.bbc.com/  \n",
              "111  https://www.washingtonpost.com/lifestyle/2023/...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4027c8f1-b469-4175-8469-45b274a9e723\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/opinions/2023/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/politics/2023/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/sports/2023/04/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/opinions/2023/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/politics/2023/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/advice/2023/04/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/business/2023/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/technology/2023...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pep say manchester city delivering option win ...</td>\n",
              "      <td>https://www.bbc.com/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/lifestyle/2023/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4027c8f1-b469-4175-8469-45b274a9e723')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4027c8f1-b469-4175-8469-45b274a9e723 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4027c8f1-b469-4175-8469-45b274a9e723');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation system without sentiment analysis"
      ],
      "metadata": {
        "id": "oPq2YXa1ZecX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect the preprocesses positve tweets for Text Blob analyzer\n",
        "recom_tweets = []\n",
        "for t in range(len(df1)):\n",
        "  recom_tweets.append(df1['ptext'][t])\n",
        "\n",
        "# Fit transform Text Blob text\n",
        "recom_tweet_features = vectorizer.transform(recom_tweets)\n",
        "\n",
        "# Compute cosine similarities between tweet features and article features\n",
        "recom_similarities = cosine_similarity(recom_tweet_features, article_features)\n",
        "\n",
        "# Get indices of top 200 articles most similar to the user's tweets\n",
        "recom_top_article_indices = recom_similarities.mean(axis=0).argsort()[::-1][:190]\n",
        "\n",
        "# Get recommended articles\n",
        "simple_recommended_user_articles = df.iloc[recom_top_article_indices][['text', 'link']]"
      ],
      "metadata": {
        "id": "VI3xHoCkZdc1"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Top recommended articles without sentiment analysis\n",
        "simple_recommended_user_articles[10:19]"
      ],
      "metadata": {
        "id": "5MR_TQjkV7kE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "7c5856ce-26f9-4877-ddc2-24f2fc9f9e64"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  \\\n",
              "132  listen min comment story comment gift article ...   \n",
              "233  john wagner national reporter post break polit...   \n",
              "158  julian business reporter education state unive...   \n",
              "174  listen min comment story comment gift article ...   \n",
              "473  hannah sampson reporter focus travel news educ...   \n",
              "486  site information policy standard washington po...   \n",
              "331  home single woman man buy home mean easy compe...   \n",
              "238  listen min comment story comment gift article ...   \n",
              "118  listen min comment story comment gift article ...   \n",
              "\n",
              "                                                  link  \n",
              "132  https://www.washingtonpost.com/opinions/2023/0...  \n",
              "233  https://www.washingtonpost.com/people/john-wag...  \n",
              "158  https://www.washingtonpost.com/people/julian-m...  \n",
              "174  https://www.washingtonpost.com/media/2023/04/2...  \n",
              "473  https://www.washingtonpost.com/people/hannah-s...  \n",
              "486  https://www.washingtonpost.com/policies-and-st...  \n",
              "331  https://www.washingtonpost.com/home/2023/04/26...  \n",
              "238  https://www.washingtonpost.com/politics/2023/0...  \n",
              "118  https://www.washingtonpost.com/opinions/2023/0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a34c3624-889b-476f-8649-42358957ec88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/opinions/2023/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>john wagner national reporter post break polit...</td>\n",
              "      <td>https://www.washingtonpost.com/people/john-wag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>julian business reporter education state unive...</td>\n",
              "      <td>https://www.washingtonpost.com/people/julian-m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/media/2023/04/2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>hannah sampson reporter focus travel news educ...</td>\n",
              "      <td>https://www.washingtonpost.com/people/hannah-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>site information policy standard washington po...</td>\n",
              "      <td>https://www.washingtonpost.com/policies-and-st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>home single woman man buy home mean easy compe...</td>\n",
              "      <td>https://www.washingtonpost.com/home/2023/04/26...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/politics/2023/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>listen min comment story comment gift article ...</td>\n",
              "      <td>https://www.washingtonpost.com/opinions/2023/0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a34c3624-889b-476f-8649-42358957ec88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a34c3624-889b-476f-8649-42358957ec88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a34c3624-889b-476f-8649-42358957ec88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import spacy\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# # assume `df` is your dataframe of news articles\n",
        "\n",
        "# def recommend_articles(tweet_text, df):\n",
        "#     # preprocess tweet text\n",
        "#     tweet_doc = nlp(tweet_text.lower())\n",
        "#     tweet_keywords = [token.lemma_ for token in tweet_doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
        "\n",
        "#     # search for articles that contain at least one of the tweet keywords in the title or text\n",
        "#     matching_articles = df[df.apply(lambda x: any(keyword in x['text'].lower() for keyword in tweet_keywords), axis=1)]\n",
        "\n",
        "#     # return top 5 matching articles\n",
        "#     return matching_articles.head(10)"
      ],
      "metadata": {
        "id": "G62738O40NXj"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function defination for jaccard similarity score on the follwoing models\n",
        "import math\n",
        "def get_jaccard_sim(set1, set2): \n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    sim = float(len(intersection) / len(union))\n",
        "    return  float(sim)"
      ],
      "metadata": {
        "id": "as6C1DXDv55r"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Store the dataframe 'text' into a single list\n",
        "twts = []\n",
        "sent_recom = []\n",
        "recom = []\n",
        "for i in df['text']:\n",
        "  twts.append(i)\n",
        "for i in sentiment_recommended_user_articles['text']:\n",
        "  sent_recom.append(i)\n",
        "for i in simple_recommended_user_articles['text']:\n",
        "  recom.append(i)"
      ],
      "metadata": {
        "id": "RhPvW71tPWWz"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result comporision through similarity score"
      ],
      "metadata": {
        "id": "WycHucs-cSkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jaccard similarity score of the actual articles and the recommended articles using sentiment analysis\n",
        "get_jaccard_sim(set(twts),set(sent_recom))"
      ],
      "metadata": {
        "id": "oCVLfJmRxyZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba93d7d6-2320-477d-ae67-a84be312226b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8116438356164384"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jaccard similarity score of the actual articles and the recommended articles without sentiment analysis\n",
        "get_jaccard_sim(set(twts),set(recom))"
      ],
      "metadata": {
        "id": "lWrYgHb-v1gL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50483fb9-a2e2-4ad1-db32-04218d01dbf9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6335616438356164"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "QV16jZWgcPll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Jaccard similarity is a popular similarity measure in recommendation systems that evaluates how similar two collections of items are to one another. It relies on the hunch that two collections of items that have a lot of overlap might have a connection to one another. The jaccard similarity ranges from 0.0 to 1.0. The higher the jaccard similarity of the two sets, the higher the implication that they are connected to each other.\n",
        "\n",
        "After running the colab file models multiple times we see that the jaccard similarity score of simple recommendation system is less than recommendation system with sentiment analysis. The sentiment recommendation system is having higher similarity because it is recommending user the articles based on the sentiments of the users which is more close to the actual recommendations provided."
      ],
      "metadata": {
        "id": "s8YWYB8yjr2G"
      }
    }
  ]
}